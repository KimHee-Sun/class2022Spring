{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "huggingface_gradio.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimHee-Sun/class2022Spring/blob/main/huggingface_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIc3wBXqPoAi"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- huggingface의 모델을 그대로 가져와서 바로 실행할 수도 있음 (gpt2)"
      ],
      "metadata": {
        "id": "wkrDZe9vQl7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Image classification](https://huggingface.co/tasks/image-classification)"
      ],
      "metadata": {
        "id": "HiGiIwHHXyJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/google/vit-base-patch16-224 \\\n",
        "How to use\n",
        "\n",
        "\n",
        "☝ **정확히 만들 수는 없더라도, 어떤 것을 의미하는 지는 알아야 함**"
      ],
      "metadata": {
        "id": "N85f15SRXtON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "gJatB6PFZdse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "#1) 필요한 것을 import 해오기\n",
        "\n",
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "#2) 필요한 이미지를 가져와야 함 (업로드하지 않을거면 url로 가져오기, jpg를 통해 이미지인 것을 알 수 있음)\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "#3) 이 이미지 안에는 데이터가 숫자로 있다는 것을 알아야 함\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "#pretrained: 행렬, 데이터로부터 잘 만들어진 행렬 (돈의 가치가 있는 행렬)\n",
        "#5) feature_extractor: extraction을 할 수 있는 모델 -> 현재 3) 단계에서 숫자 정보가 있는데 (칼라면 3array, 흑백이면 2array), 이것을 다 쓰기에는 너무나 많으므로 압축적으로 쓸 수 있는 정보를 뽑는 것\n",
        "#6) Classification: extracted 된 feature 정보를 가지고 classify하는 것\n",
        "\n",
        "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "#이러한 feature data (5)를 inputs으로 \n",
        "outputs = model(**inputs)\n",
        "#model의 입력으로 들어가는 것, output이 classify된 정보가 나오는 것\n",
        "logits = outputs.logits\n",
        "# model predicts one of the 1000 ImageNet classes\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n",
        "#해당 그림을 Egyptian cat이라고 인식한 것, 1,000개의 idx 즉 class가 있는데 그것 중에 하나를 predict 해내는 것임\n",
        "#1,000개의 class에 대한 확률이 모두 나오고, 이 중에 가장 확률이 높은 것 (argmx)를 찾았는데 이것이 Egyptian Cat이라고 보면됨 -> 1,000개의 숫자를 다 합치면 1!\n",
        "#현재 id2lable은 script의 형태, 숫자가 쭉 나오는 것"
      ],
      "metadata": {
        "id": "ldZauC4yXfBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "CR7IwXS5Ybbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func (image):\n",
        "  #위에 있는 것의 일부를 떼와서 function화\n",
        "  #image가 input ( model.config.id2label[predicted_class_idx])) -> 여기 부분!\n",
        "  feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "  model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "  inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "  outputs = model(**inputs)\n",
        "  logits = outputs.logits\n",
        "  # model predicts one of the 1000 ImageNet classes\n",
        "  predicted_class_idx = logits.argmax(-1).item()\n",
        "  predicted_class = model.config.id2label[predicted_class_idx]\n",
        "  #출력, 변수로 받은 것 \n",
        "  #image를 받아서 그것의 class를 text로 return\n",
        "  return predicted_class\n",
        "  # model.config.id2label[predicted_class_idx]) 여기 부분인 것!"
      ],
      "metadata": {
        "id": "CA35L2ZPZveq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/tiger.jpg\"\n",
        "os.system(\"curl \" + url + \" > tiger.jpg\")\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/dog.jpg\"\n",
        "os.system(\"curl \" + url + \" > dog.jpg\")"
      ],
      "metadata": {
        "id": "v4FSg0gMbBLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='image', outputs='text', examples = ['tiger.jpg', 'dog.jpg']).launch()\n",
        "#function, inputs, outputs 정해주고 출력유형을 정해서 (image, text) launch\n",
        "#examples로 사진 두개를 넣기 위해서 url로 이미지 사진 두개 받아줌 (반드시 list로 넣어주어야 함) -> demo를 만드는 gradio에서 사용할 수 있는 강점임 "
      ],
      "metadata": {
        "id": "h3N3dCkG2o3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Fill-Mask](https://huggingface.co/tasks/fill-mask)"
      ],
      "metadata": {
        "id": "Z8kY0va6YuS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/bert-base-uncased \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "IGD_q0SXfCF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "zR23S_FtfIkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "#이 model을 가져와서 unmasker라고 하겠다\n",
        "unmasker(\"Hello I'm a [MASK] model.\")\n",
        "#이 model을 실행"
      ],
      "metadata": {
        "id": "spM_LYGees_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "KaobDkL0fRJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def func (text):\n",
        "  unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "  result = unmasker(text)\n",
        "  df = pd.DataFrame(result)\n",
        "  #위 모델의 결과값이 list 형태, 따라서 dataframe으로 만들 수 있음\n",
        "  return df"
      ],
      "metadata": {
        "id": "3CKQl_oDfTsd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\"Hello I'm a [MASK] model.\", \"It is raining outside. I feel [MASK].\"]"
      ],
      "metadata": {
        "id": "-OkQDYW2wju6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe', examples = examples).launch()"
      ],
      "metadata": {
        "id": "1aGFWiTUfl9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Token classification](https://huggingface.co/tasks/token-classification)"
      ],
      "metadata": {
        "id": "0DDckwQ50cRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/dslim/bert-base-NER \\\n",
        "How to use\n",
        "\n",
        "- 정보 중에서 더욱 salient한 것을 recognize해내는 것 = NER!(LOC, ORG, PER, MISC)"
      ],
      "metadata": {
        "id": "mxv4tEUM0y_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "hUVn8h1304DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."
      ],
      "metadata": {
        "id": "9ksySb1Q50wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "#image classification과 유사하게 pretained를 불러옴 -> tokenizer라는 모델로 받았음\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "#각 단어를 classification 해주는 것을 NER, 4가지 종류\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "example = \"My name is Wolfgang and I live in Berlin\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "#위에 있는 example 문장을 가지고 위에 nlp 모델을 돌림\n",
        "print(ner_results)\n",
        "#이것도 list이므로 df할 수 있음"
      ],
      "metadata": {
        "id": "d9UOCPGJ0b1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "1CuE0WLi0x7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "def func (text):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "  model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "  nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "  result = nlp(text)\n",
        "  df = pd.DataFrame(result)\n",
        "  #list로 dictionary 안에 여러개가 있을 때 바로 dataframe화해줄 수 있음\n",
        "  return df"
      ],
      "metadata": {
        "id": "jlx5iyV_0xV9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\"My name is Wolfgang and I live in Berlin\", \"I will visit Seoul to see Chris\"]"
      ],
      "metadata": {
        "id": "upMTUXmc4fip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe', examples = examples).launch()"
      ],
      "metadata": {
        "id": "Nes4r_Ek4fYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Sentence similarity](https://huggingface.co/tasks/sentence-similarity)"
      ],
      "metadata": {
        "id": "dE0umBRo7knv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 \\\n",
        "How to use\n",
        "\n",
        "- 모든 text, sound, image의 raw data는 숫자로 되어 있다고 하더라도, 바로 model input으로 넣어줄 수 없음 -> 따라서 feature로 만들기도 하고, vectors, embeddings라고 하기도 함"
      ],
      "metadata": {
        "id": "WJByl36a7lbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "lZvWkGmwAasZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sentences = [\"This is an example sentence\", \"it is one example writing\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "#이 model의 input으로 위의 문장을 쓰면 embeddings로 출력해준다\n",
        "#embeddings란? [[~~ 384개의 숫자] [~~384개의 숫자]]가 있음 -> 이것을 embeddings for text 1, text2라고 부르며 feature, vector (숫자들의 열이니까)\n",
        "#-> 이것을 가지고 유사도를 어떻게 찾는가? goodnotes 참고 (**매우 매우 중요**)\n",
        "#=similarity between two vectors (=embeddings) = 두 각도 값의 cos vector 값 =cosine similarity => 차원이 많아진다고 하더라도, 두 벡터는 원점과 함께 평면을 이루고 삼각형을 만들게 되어 있음\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "ahXHjR-x7nP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[1])"
      ],
      "metadata": {
        "id": "z9tLd396Hthr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_scores = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "#cosine similarity 계산 해주는 것, 두개의 vector (=embeddings)를 넣어주면 됨 (각 text의 384개의 숫자)\n",
        "cosine_scores"
      ],
      "metadata": {
        "id": "Ne5AH2qbCZy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "As33TUuTcJH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func (text1, text2):\n",
        "  from sentence_transformers import SentenceTransformer, util\n",
        "  model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "  embeddings = model.encode([text1, text2])\n",
        "  cosine_scores = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "  return cosine_scores"
      ],
      "metadata": {
        "id": "XqwC0HHicM71"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [[\"This is an example sentence\", \"it is one example writing\"], [\"A frog is hopping near the pond\", \"I love Korean Food\"]]"
      ],
      "metadata": {
        "id": "zZMVURDWcTNf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs=['text', 'text'], outputs='number', examples = examples).launch()"
      ],
      "metadata": {
        "id": "1pbOXexycTGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PWU2fhR1IDc9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}